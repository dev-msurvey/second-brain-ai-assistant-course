{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ AI Director: Meta Ax Hyperparameter Optimization (Standalone)\n",
    "\n",
    "**Module 4.5: Bayesian Optimization for LoRA Training**\n",
    "\n",
    "This notebook uses **Meta Ax** to find optimal hyperparameters.\n",
    "\n",
    "**Target**: Beat baseline loss of 0.6097  \n",
    "**Time**: ~2.5 hours on T4 GPU (20 trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q torch transformers peft datasets accelerate bitsandbytes ax-platform botorch gpytorch loguru pandas pyyaml scipy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATASET_PATH = '/content/drive/MyDrive/ai_director_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'search_space': {\n",
    "        'lora_rank': {'type': 'choice', 'values': [8, 16, 32, 64]},\n",
    "        'lora_alpha': {'type': 'choice', 'values': [16, 32, 64, 128]},\n",
    "        'learning_rate': {'type': 'range', 'bounds': [0.00001, 0.0005], 'log_scale': True},\n",
    "        'batch_size': {'type': 'choice', 'values': [1, 2, 4]}\n",
    "    },\n",
    "    'baseline': {'loss': 0.6097},\n",
    "    'num_trials': 20,\n",
    "    'dataset_path': DATASET_PATH\n",
    "}\n",
    "print(f\"Target: Beat {CONFIG['baseline']['loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from datasets import load_dataset\n",
    "\n",
    "@dataclass\n",
    "class FineTuningConfig:\n",
    "    base_model: str = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "    max_seq_length: int = 2048\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: int = 32\n",
    "    lora_dropout: float = 0.05\n",
    "    target_modules: List[str] = field(default_factory=lambda: [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"])\n",
    "    num_train_epochs: int = 1\n",
    "    per_device_train_batch_size: int = 1\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    learning_rate: float = 2e-4\n",
    "    warmup_ratio: float = 0.1\n",
    "    logging_steps: int = 5\n",
    "    eval_steps: int = 50\n",
    "    save_steps: int = 50\n",
    "    dataset_path: str = \"/content/drive/MyDrive/ai_director_dataset\"\n",
    "    output_dir: str = \"/content/models/temp\"\n",
    "\n",
    "class AIDirectorFineTuner:\n",
    "    def __init__(self, config: FineTuningConfig):\n",
    "        self.config = config\n",
    "        self.output_dir = Path(config.output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.dataset = None\n",
    "    \n",
    "    def load_tokenizer(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.config.base_model, trust_remote_code=True)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "    \n",
    "    def load_model(self):\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_use_double_quant=True\n",
    "        )\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.config.base_model,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        self.model = prepare_model_for_kbit_training(self.model)\n",
    "    \n",
    "    def apply_lora(self):\n",
    "        lora_config = LoraConfig(\n",
    "            r=self.config.lora_r,\n",
    "            lora_alpha=self.config.lora_alpha,\n",
    "            target_modules=self.config.target_modules,\n",
    "            lora_dropout=self.config.lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=TaskType.CAUSAL_LM\n",
    "        )\n",
    "        self.model = get_peft_model(self.model, lora_config)\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        dataset_path = Path(self.config.dataset_path)\n",
    "        self.dataset = load_dataset(\"json\", data_files={\n",
    "            \"train\": str(dataset_path / \"train_v2.jsonl\"),\n",
    "            \"validation\": str(dataset_path / \"val_v2.jsonl\")\n",
    "        })\n",
    "        \n",
    "        def format_prompt(sample):\n",
    "            return f'''<|im_start|>system\\nYou are an AI Director.<|im_end|>\\n<|im_start|>user\\n{sample[\"instruction\"]}\\n\\n{sample[\"input\"]}<|im_end|>\\n<|im_start|>assistant\\n{sample[\"output\"]}<|im_end|>'''\n",
    "        \n",
    "        def tokenize(examples):\n",
    "            texts = [format_prompt(ex) for ex in examples]\n",
    "            tok = self.tokenizer(texts, truncation=True, max_length=self.config.max_seq_length, padding=\"max_length\")\n",
    "            tok[\"labels\"] = tok[\"input_ids\"].copy()\n",
    "            return tok\n",
    "        \n",
    "        self.dataset[\"train\"] = self.dataset[\"train\"].map(lambda x: tokenize([x]), batched=False)\n",
    "        self.dataset[\"validation\"] = self.dataset[\"validation\"].map(lambda x: tokenize([x]), batched=False)\n",
    "    \n",
    "    def train(self):\n",
    "        args = TrainingArguments(\n",
    "            output_dir=str(self.output_dir),\n",
    "            num_train_epochs=self.config.num_train_epochs,\n",
    "            per_device_train_batch_size=self.config.per_device_train_batch_size,\n",
    "            gradient_accumulation_steps=self.config.gradient_accumulation_steps,\n",
    "            learning_rate=self.config.learning_rate,\n",
    "            warmup_ratio=self.config.warmup_ratio,\n",
    "            logging_steps=self.config.logging_steps,\n",
    "            eval_steps=self.config.eval_steps,\n",
    "            save_steps=self.config.save_steps,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            save_strategy=\"steps\",\n",
    "            load_best_model_at_end=True,\n",
    "            bf16=True,\n",
    "            report_to=[]\n",
    "        )\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=args,\n",
    "            train_dataset=self.dataset[\"train\"],\n",
    "            eval_dataset=self.dataset[\"validation\"],\n",
    "            data_collator=DataCollatorForLanguageModeling(self.tokenizer, mlm=False)\n",
    "        )\n",
    "        result = trainer.train()\n",
    "        eval_result = trainer.evaluate()\n",
    "        return {'eval_loss': eval_result['eval_loss']}\n",
    "\n",
    "print(\"‚úÖ Training function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Optimization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.service.utils.instantiation import ObjectiveProperties\n",
    "\n",
    "class HyperparameterOptimizer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.ax_client = None\n",
    "        self.trial_results = []\n",
    "    \n",
    "    def setup_ax(self):\n",
    "        self.ax_client = AxClient()\n",
    "        parameters = []\n",
    "        for name, cfg in self.config['search_space'].items():\n",
    "            if cfg['type'] == 'choice':\n",
    "                parameters.append({\"name\": name, \"type\": \"choice\", \"values\": cfg['values'], \"value_type\": \"int\"})\n",
    "            elif cfg['type'] == 'range':\n",
    "                parameters.append({\"name\": name, \"type\": \"range\", \"bounds\": cfg['bounds'], \"value_type\": \"float\", \"log_scale\": cfg.get('log_scale', False)})\n",
    "        \n",
    "        self.ax_client.create_experiment(\n",
    "            name=\"ai_director_optimization\",\n",
    "            parameters=parameters,\n",
    "            objectives={\"eval_loss\": ObjectiveProperties(minimize=True)}\n",
    "        )\n",
    "        print(\"‚úÖ Ax setup complete\")\n",
    "    \n",
    "    def evaluate(self, params):\n",
    "        print(f\"\\nüî¨ Trial: {params}\")\n",
    "        try:\n",
    "            cfg = FineTuningConfig(\n",
    "                lora_r=params['lora_rank'],\n",
    "                lora_alpha=params['lora_alpha'],\n",
    "                learning_rate=params['learning_rate'],\n",
    "                per_device_train_batch_size=params['batch_size'],\n",
    "                output_dir=f\"/content/models/trial_{datetime.now():%H%M%S}\",\n",
    "                dataset_path=self.config['dataset_path']\n",
    "            )\n",
    "            trainer = AIDirectorFineTuner(cfg)\n",
    "            trainer.load_tokenizer()\n",
    "            trainer.load_model()\n",
    "            trainer.apply_lora()\n",
    "            trainer.load_dataset()\n",
    "            result = trainer.train()\n",
    "            loss = result['eval_loss']\n",
    "            print(f\"‚úÖ Loss: {loss:.4f}\")\n",
    "            if Path(cfg.output_dir).exists():\n",
    "                shutil.rmtree(cfg.output_dir)\n",
    "            return loss\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            return 1.0\n",
    "    \n",
    "    def run(self, num_trials=None):\n",
    "        if num_trials is None:\n",
    "            num_trials = self.config['num_trials']\n",
    "        \n",
    "        self.setup_ax()\n",
    "        print(f\"\\nüöÄ Starting {num_trials} trials...\\n\")\n",
    "        \n",
    "        for i in range(num_trials):\n",
    "            print(f\"\\n{'#'*50}\\nTRIAL {i+1}/{num_trials}\\n{'#'*50}\")\n",
    "            params, trial_idx = self.ax_client.get_next_trial()\n",
    "            loss = self.evaluate(params)\n",
    "            self.ax_client.complete_trial(trial_index=trial_idx, raw_data=loss)\n",
    "            self.trial_results.append({'trial': i+1, 'params': params, 'loss': loss})\n",
    "        \n",
    "        best_params, values = self.ax_client.get_best_parameters()\n",
    "        best_loss = values[0]['eval_loss']\n",
    "        improvement = (self.config['baseline']['loss'] - best_loss) / self.config['baseline']['loss'] * 100\n",
    "        \n",
    "        print(f\"\\n{'='*50}\\nüèÜ RESULTS\\n{'='*50}\")\n",
    "        print(f\"Best: {best_params}\")\n",
    "        print(f\"Loss: {best_loss:.4f} (baseline: {self.config['baseline']['loss']:.4f})\")\n",
    "        print(f\"Improvement: {improvement:+.1f}%\")\n",
    "        \n",
    "        return {'best_params': best_params, 'best_loss': best_loss, 'improvement': improvement, 'trials': self.trial_results}\n",
    "\n",
    "print(\"‚úÖ Optimizer ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Run Optimization üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = HyperparameterOptimizer(CONFIG)\n",
    "results = optimizer.run(num_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "output_dir = Path('/content/drive/MyDrive/ai_director_optimization_results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# JSON\n",
    "with open(output_dir / 'results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# YAML\n",
    "with open(output_dir / 'best_config.yaml', 'w') as f:\n",
    "    yaml.dump(results['best_params'], f)\n",
    "\n",
    "print(f\"‚úÖ Saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trials = [r['trial'] for r in results['trials']]\n",
    "losses = [r['loss'] for r in results['trials']]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(trials, losses, 'bo-')\n",
    "plt.axhline(y=CONFIG['baseline']['loss'], color='r', linestyle='--', label='Baseline')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Optimization Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(output_dir / 'plot.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"üéØ SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best Loss: {results['best_loss']:.4f}\")\n",
    "print(f\"Improvement: {results['improvement']:+.1f}%\")\n",
    "print(f\"Best Config: {results['best_params']}\")\n",
    "print(f\"\\nResults saved to Google Drive: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
