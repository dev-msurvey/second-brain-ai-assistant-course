#!/usr/bin/env python3
"""
RAG-Enhanced Inference Script for AI Director (Module 4)

à¹à¸™à¸§à¸„à¸´à¸”: Fine-tuning à¸ªà¸­à¸™ "à¸—à¸±à¸à¸©à¸°" (Skill) + RAG à¸›à¹‰à¸­à¸™ "à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰" (Knowledge)
- Fine-tuned model: à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸§à¸´à¸˜à¸µà¹€à¸‚à¸µà¸¢à¸™ caption, brief, tone adaptation
- RAG: à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸šà¸£à¸™à¸”à¹Œà¸ˆà¸²à¸ brands.json à¸¡à¸²à¹ƒà¸ªà¹ˆà¹ƒà¸™ prompt

à¸‚à¹‰à¸­à¸”à¸µ:
âœ… à¸£à¸­à¸‡à¸£à¸±à¸šà¹à¸šà¸£à¸™à¸”à¹Œà¹ƒà¸«à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µà¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ retrain
âœ… à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸±à¸›à¹€à¸”à¸•à¹à¸šà¸š real-time (à¹à¸à¹‰ brands.json à¹„à¸”à¹‰à¹€à¸¥à¸¢)
âœ… à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ hallucination (à¹‚à¸¡à¹€à¸”à¸¥à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ˆà¸³ brand details)
âœ… Scalable à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸°à¸šà¸š production

Architecture:
Input (User) â†’ RAG Retrieval (brands.json) â†’ Enriched Prompt â†’ Fine-tuned Model â†’ Output
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
from loguru import logger


@dataclass
class BrandContext:
    """Brand information retrieved from RAG"""
    name: str
    description: str
    tone: List[str]
    target_audience: str
    core_values: List[str]
    visual_style: Optional[str] = None
    
    def to_prompt_string(self) -> str:
        """à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ string à¸—à¸µà¹ˆà¹ƒà¸ªà¹ˆà¹ƒà¸™ prompt à¹„à¸”à¹‰"""
        tone_str = ", ".join(self.tone)
        values_str = ", ".join(self.core_values)
        
        result = f"""Brand: {self.name}
Description: {self.description}
Tone: {tone_str}
Target Audience: {self.target_audience}
Core Values: {values_str}"""
        
        if self.visual_style:
            result += f"\nVisual Style: {self.visual_style}"
        
        return result


class BrandRAG:
    """
    Retrieval-Augmented Generation for Brand Context
    
    à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸šà¸£à¸™à¸”à¹Œà¸ˆà¸²à¸ brands_v2.json à¹à¸—à¸™à¸à¸²à¸£à¹ƒà¸«à¹‰à¹‚à¸¡à¹€à¸”à¸¥à¸ˆà¸³
    """
    
    def __init__(self, brands_json_path: str):
        self.brands_json_path = Path(brands_json_path)
        self.brands_db: Dict[str, Dict] = {}
        self._load_brands()
    
    def _load_brands(self):
        """à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸šà¸£à¸™à¸”à¹Œà¸ˆà¸²à¸ JSON"""
        if not self.brands_json_path.exists():
            logger.warning(f"âŒ à¹„à¸¡à¹ˆà¸à¸šà¹„à¸Ÿà¸¥à¹Œ {self.brands_json_path}")
            return
        
        with open(self.brands_json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        # à¸ªà¸¡à¸¡à¸•à¸´à¸§à¹ˆà¸² structure à¸„à¸·à¸­ {"brands": [...]}
        brands_list = data.get("brands", [])
        
        for brand in brands_list:
            brand_name = brand.get("name", "")
            self.brands_db[brand_name.lower()] = brand
        
        logger.info(f"âœ… à¹‚à¸«à¸¥à¸”à¹à¸šà¸£à¸™à¸”à¹Œ {len(self.brands_db)} à¹à¸šà¸£à¸™à¸”à¹Œà¸ˆà¸²à¸ RAG: {list(self.brands_db.keys())}")
    
    def retrieve(self, brand_name: str) -> Optional[BrandContext]:
        """
        à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸šà¸£à¸™à¸”à¹Œà¸ˆà¸²à¸ database
        
        Args:
            brand_name: à¸Šà¸·à¹ˆà¸­à¹à¸šà¸£à¸™à¸”à¹Œ (à¹€à¸Šà¹ˆà¸™ "CoffeeLab", "TechZone")
        
        Returns:
            BrandContext à¸–à¹‰à¸²à¹€à¸ˆà¸­, None à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¹€à¸ˆà¸­
        """
        brand_key = brand_name.lower()
        
        if brand_key not in self.brands_db:
            logger.warning(f"âš ï¸  à¹„à¸¡à¹ˆà¸à¸šà¹à¸šà¸£à¸™à¸”à¹Œ '{brand_name}' à¹ƒà¸™ RAG database")
            return None
        
        brand_data = self.brands_db[brand_key]
        
        return BrandContext(
            name=brand_data.get("name", brand_name),
            description=brand_data.get("description", ""),
            tone=brand_data.get("tone", []),
            target_audience=brand_data.get("target_audience", ""),
            core_values=brand_data.get("core_values", []),
            visual_style=brand_data.get("visual_style")
        )
    
    def list_available_brands(self) -> List[str]:
        """à¹à¸ªà¸”à¸‡à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¹à¸šà¸£à¸™à¸”à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¹ƒà¸™ database"""
        return list(self.brands_db.keys())


class AIDirectorRAGInference:
    """
    AI Director Inference Engine with RAG Support
    
    à¹ƒà¸Šà¹‰ RAG à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸šà¸£à¸™à¸”à¹Œà¸¡à¸²à¹ƒà¸ªà¹ˆà¹ƒà¸™ prompt â†’ à¸ªà¹ˆà¸‡à¹ƒà¸«à¹‰ fine-tuned model à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥
    """
    
    def __init__(
        self,
        base_model_path: str = "Qwen/Qwen2.5-7B-Instruct",
        lora_adapter_path: Optional[str] = None,
        brands_json_path: str = "../../module2/data/raw/brands_v2.json",
        device: str = "auto"
    ):
        self.device = device
        self.tokenizer = None
        self.model = None
        self.rag = BrandRAG(brands_json_path)
        
        logger.info("ğŸ”§ à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸” tokenizer à¹à¸¥à¸°à¹‚à¸¡à¹€à¸”à¸¥...")
        self._load_model(base_model_path, lora_adapter_path)
    
    def _load_model(self, base_model_path: str, lora_adapter_path: Optional[str]):
        """à¹‚à¸«à¸¥à¸” base model + LoRA adapter (à¸–à¹‰à¸²à¸¡à¸µ)"""
        
        # à¹‚à¸«à¸¥à¸” tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            base_model_path,
            trust_remote_code=True
        )
        self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # à¹‚à¸«à¸¥à¸” base model
        self.model = AutoModelForCausalLM.from_pretrained(
            base_model_path,
            torch_dtype=torch.float16,
            device_map=self.device,
            trust_remote_code=True
        )
        
        # à¹‚à¸«à¸¥à¸” LoRA adapter (à¸–à¹‰à¸² fine-tune à¹à¸¥à¹‰à¸§)
        if lora_adapter_path and os.path.exists(lora_adapter_path):
            logger.info(f"ğŸ¯ à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸” LoRA adapter à¸ˆà¸²à¸ {lora_adapter_path}")
            self.model = PeftModel.from_pretrained(self.model, lora_adapter_path)
            self.model = self.model.merge_and_unload()  # Merge à¹€à¸à¸·à¹ˆà¸­ inference à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™
            logger.info("âœ… à¹‚à¸«à¸¥à¸” fine-tuned model à¸ªà¸³à¹€à¸£à¹‡à¸ˆ (à¸—à¸±à¸à¸©à¸°à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰)")
        else:
            logger.warning("âš ï¸  à¹ƒà¸Šà¹‰ base model (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ fine-tune)")
        
        self.model.eval()
    
    def generate(
        self,
        instruction: str,
        brand_name: Optional[str] = None,
        additional_context: Optional[str] = None,
        max_new_tokens: int = 256,
        temperature: float = 0.7,
        top_p: float = 0.9
    ) -> str:
        """
        Generate content with RAG support
        
        Args:
            instruction: à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ (à¹€à¸Šà¹ˆà¸™ "à¹€à¸‚à¸µà¸¢à¸™ caption à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸à¸ªà¸•à¹Œà¸§à¸±à¸™à¸«à¸¢à¸¸à¸”")
            brand_name: à¸Šà¸·à¹ˆà¸­à¹à¸šà¸£à¸™à¸”à¹Œ (à¸ˆà¸°à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ RAG à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´)
            additional_context: Context à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡ (à¹€à¸Šà¹ˆà¸™ "Product launch")
            max_new_tokens: à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§ output
            temperature: à¸„à¸§à¸²à¸¡à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸£à¸„à¹Œ (0.0-1.0)
            top_p: nucleus sampling
        
        Returns:
            Generated text
        """
        
        # 1. à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸šà¸£à¸™à¸”à¹Œà¸ˆà¸²à¸ RAG (à¸–à¹‰à¸²à¸¡à¸µ brand_name)
        brand_context = None
        if brand_name:
            brand_context = self.rag.retrieve(brand_name)
            
            if brand_context:
                logger.info(f"âœ… RAG: à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ {brand_name} à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
            else:
                logger.warning(f"âš ï¸  RAG: à¹„à¸¡à¹ˆà¸à¸š {brand_name} - à¸ˆà¸°à¹ƒà¸Šà¹‰ base model à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™")
        
        # 2. à¸ªà¸£à¹‰à¸²à¸‡ enriched prompt (instruction + RAG context)
        input_text = self._build_input(brand_context, additional_context)
        
        # 3. Format à¸•à¸²à¸¡ Qwen2.5 chat template
        messages = [
            {"role": "system", "content": "You are an expert AI Creative Director specializing in Thai marketing content."},
            {"role": "user", "content": f"### Instruction:\n{instruction}\n\n### Input:\n{input_text}"}
        ]
        
        prompt = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        # 4. Generate
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=top_p,
                do_sample=True,
                pad_token_id=self.tokenizer.pad_token_id
            )
        
        # 5. Decode output
        generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # à¸•à¸±à¸”à¸ªà¹ˆà¸§à¸™ prompt à¸­à¸­à¸ (à¹€à¸­à¸²à¹à¸„à¹ˆ response)
        response = self._extract_response(generated, prompt)
        
        return response
    
    def _build_input(
        self,
        brand_context: Optional[BrandContext],
        additional_context: Optional[str]
    ) -> str:
        """à¸ªà¸£à¹‰à¸²à¸‡ input text à¸ˆà¸²à¸ RAG context"""
        
        parts = []
        
        # Brand context à¸ˆà¸²à¸ RAG
        if brand_context:
            parts.append(brand_context.to_prompt_string())
        
        # Additional context (à¹€à¸Šà¹ˆà¸™ product info)
        if additional_context:
            parts.append(f"Context: {additional_context}")
        
        return "\n".join(parts) if parts else ""
    
    def _extract_response(self, generated_text: str, prompt: str) -> str:
        """à¸•à¸±à¸” prompt à¸­à¸­à¸à¸ˆà¸²à¸ generated text"""
        if prompt in generated_text:
            response = generated_text[len(prompt):].strip()
        else:
            # Fallback: à¸«à¸² <|im_start|>assistant (Qwen format)
            if "<|im_start|>assistant" in generated_text:
                response = generated_text.split("<|im_start|>assistant")[-1]
                response = response.replace("<|im_end|>", "").strip()
            else:
                response = generated_text
        
        return response
    
    # ========== Helper Methods for Common Tasks ==========
    
    def generate_caption(
        self,
        brand_name: str,
        context: str = "General post"
    ) -> str:
        """
        Generate Instagram/TikTok caption
        
        à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡:
        >>> inference.generate_caption("TechZone", "Gaming mouse launch")
        """
        instruction = f"à¹€à¸‚à¸µà¸¢à¸™ caption à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸à¸ªà¸•à¹Œ {context}"
        return self.generate(instruction, brand_name=brand_name)
    
    def generate_campaign_brief(
        self,
        brand_name: str,
        campaign_objective: str
    ) -> str:
        """
        Generate campaign brief
        
        à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡:
        >>> inference.generate_campaign_brief("TechZone", "Product launch for new gaming series")
        """
        instruction = "à¸ªà¸£à¹‰à¸²à¸‡ campaign brief"
        additional_context = f"Campaign Objective: {campaign_objective}"
        return self.generate(instruction, brand_name=brand_name, additional_context=additional_context)
    
    def adapt_brand_voice(
        self,
        brand_name: str,
        generic_message: str
    ) -> str:
        """
        Adapt generic message to brand voice
        
        à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡:
        >>> inference.adapt_brand_voice("TechZone", "à¸¡à¸²à¸¥à¸­à¸‡à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¹ƒà¸«à¸¡à¹ˆà¸à¸±à¸™à¹€à¸–à¸­à¸°")
        """
        instruction = f"à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸™à¸µà¹‰à¹ƒà¸«à¹‰à¹€à¸‚à¹‰à¸²à¸à¸±à¸š brand voice: {generic_message}"
        return self.generate(instruction, brand_name=brand_name)


def demo_comparison():
    """
    Demo: à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š 3 à¹à¸™à¸§à¸—à¸²à¸‡
    1. Base model (à¹„à¸¡à¹ˆ fine-tune, à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ RAG)
    2. Fine-tuned only (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ RAG - à¹€à¸ªà¸µà¹ˆà¸¢à¸‡ hallucinate à¸–à¹‰à¸²à¹à¸šà¸£à¸™à¸”à¹Œà¹ƒà¸«à¸¡à¹ˆ)
    3. Fine-tuned + RAG (à¹à¸™à¸°à¸™à¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸”)
    """
    
    print("\n" + "="*70)
    print("ğŸ¯ DEMO: RAG-Enhanced Inference for New Brand")
    print("="*70)
    
    # à¸ªà¸¡à¸¡à¸•à¸´à¹€à¸£à¸²à¸ªà¸£à¹‰à¸²à¸‡à¹à¸šà¸£à¸™à¸”à¹Œà¹ƒà¸«à¸¡à¹ˆà¸Šà¸·à¹ˆà¸­ "TechZone" (à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸™ train.jsonl)
    new_brand = {
        "name": "TechZone",
        "description": "à¸£à¹‰à¸²à¸™à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¹€à¸à¸¡à¸¡à¸´à¹ˆà¸‡à¹à¸¥à¸°à¹„à¸­à¸—à¸µà¸„à¸£à¸šà¸§à¸‡à¸ˆà¸£",
        "tone": ["à¸¥à¹‰à¸³à¸ªà¸¡à¸±à¸¢", "à¸£à¸§à¸”à¹€à¸£à¹‡à¸§", "à¹€à¸—à¹ˆ"],
        "target_audience": "Gamers à¸§à¸±à¸¢à¸£à¸¸à¹ˆà¸™-à¸§à¸±à¸¢à¸—à¸³à¸‡à¸²à¸™ 18-35 à¸›à¸µ",
        "core_values": ["Performance First", "Cutting Edge Tech", "Gamer Community"]
    }
    
    print(f"\nğŸ“¦ à¹à¸šà¸£à¸™à¸”à¹Œà¹ƒà¸«à¸¡à¹ˆ: {new_brand['name']}")
    print(f"   (à¹à¸šà¸£à¸™à¸”à¹Œà¸™à¸µà¹‰à¹„à¸¡à¹ˆà¹€à¸„à¸¢à¹€à¸ˆà¸­à¹ƒà¸™ train.jsonl à¹€à¸¥à¸¢)")
    print(f"   Tone: {', '.join(new_brand['tone'])}")
    
    print("\n" + "-"*70)
    print("ğŸ“ Task: à¹€à¸‚à¸µà¸¢à¸™ caption à¸›à¸£à¸°à¸à¸²à¸¨à¸‚à¸²à¸¢ Gaming Mouse")
    print("-"*70)
    
    # NOTE: à¹ƒà¸™ demo à¸ˆà¸£à¸´à¸‡ à¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¹à¸à¹‰ brands.json à¹ƒà¸«à¹‰à¸¡à¸µ TechZone à¸à¹ˆà¸­à¸™
    # à¸«à¸£à¸·à¸­à¸ˆà¸° mock à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¹‡à¹„à¸”à¹‰
    
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ à¹à¸™à¸§à¸—à¸²à¸‡ 1: Base Model (à¹„à¸¡à¹ˆ fine-tune, à¹„à¸¡à¹ˆ RAG)                   â”‚
â”‚ à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ: à¹„à¸”à¹‰ caption à¸—à¸±à¹ˆà¸§à¹„à¸› à¹„à¸¡à¹ˆà¸¡à¸µ brand voice à¹€à¸‰à¸à¸²à¸°            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

"à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¹€à¸¡à¸²à¸ªà¹Œà¹€à¸à¸¡à¸¡à¸´à¹ˆà¸‡à¸•à¸±à¸§à¹ƒà¸«à¸¡à¹ˆà¸‚à¸­à¸‡à¹€à¸£à¸²à¸ªà¸´! ğŸ–±ï¸"

âŒ à¸›à¸±à¸à¸«à¸²: à¹„à¸¡à¹ˆà¸¡à¸µ tone, à¹„à¸¡à¹ˆà¸¡à¸µ hashtag, à¸”à¸¹à¹„à¸¡à¹ˆà¸¡à¸µ brand identity

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ à¹à¸™à¸§à¸—à¸²à¸‡ 2: Fine-tuned Only (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ RAG)                         â”‚
â”‚ à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ: à¹€à¸ªà¸µà¹ˆà¸¢à¸‡ hallucinate à¹€à¸à¸£à¸²à¸°à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸ˆà¸±à¸ TechZone             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

"à¹€à¸•à¸´à¸¡à¸à¸¥à¸±à¸‡à¹€à¸Šà¹‰à¸²à¸§à¸±à¸™à¹ƒà¸«à¸¡à¹ˆà¸à¸±à¸šà¹€à¸¡à¸²à¸ªà¹Œ Gaming Mouse à¸ˆà¸²à¸ TechZone â˜•"

âŒ à¸›à¸±à¸à¸«à¸²: à¹ƒà¸Šà¹‰ tone à¸‚à¸­à¸‡ CoffeeLab (à¹€à¸•à¸´à¸¡à¸à¸¥à¸±à¸‡à¹€à¸Šà¹‰à¸²) à¸¡à¸²à¸›à¸™à¸à¸±à¸š TechZone
         à¹€à¸à¸£à¸²à¸°à¹‚à¸¡à¹€à¸”à¸¥à¸ˆà¸³à¹„à¸”à¹‰à¹à¸„à¹ˆà¸§à¹ˆà¸² "caption à¸—à¸µà¹ˆà¸”à¸µà¸•à¹‰à¸­à¸‡à¸¡à¸µà¸„à¸³à¸à¸§à¸à¸™à¸µà¹‰"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ à¹à¸™à¸§à¸—à¸²à¸‡ 3: Fine-tuned + RAG (âœ… à¹à¸™à¸°à¸™à¸³)                           â”‚
â”‚ à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ: RAG à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ TechZone à¸¡à¸²à¹ƒà¸ªà¹ˆà¹ƒà¸™ prompt                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

"ğŸ® Level Up Your Game! Gaming Mouse à¸•à¸±à¸§à¹ƒà¸«à¸¡à¹ˆ
à¸ªà¹€à¸›à¸à¹€à¸—à¸ à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡à¹€à¸£à¹‡à¸§à¸—à¸±à¸™à¹ƒà¸ˆ
à¸ªà¸³à¸«à¸£à¸±à¸š Gamers à¸•à¸±à¸§à¸ˆà¸£à¸´à¸‡ ğŸ”¥
#TechZone #PerformanceFirst #GamingGear"

âœ… à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¹à¸šà¸š:
   â€¢ à¹ƒà¸Šà¹‰ tone à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ (à¸¥à¹‰à¸³à¸ªà¸¡à¸±à¸¢, à¸£à¸§à¸”à¹€à¸£à¹‡à¸§, à¹€à¸—à¹ˆ)
   â€¢ à¸¡à¸µ emoji à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸à¸±à¸šà¹à¸šà¸£à¸™à¸”à¹Œ (ğŸ®ğŸ”¥ à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ â˜•)
   â€¢ Core values à¸–à¸¹à¸à¸ªà¸­à¸”à¹à¸—à¸£à¸ (Performance First)
   â€¢ Hashtag à¹€à¸‰à¸à¸²à¸°à¹à¸šà¸£à¸™à¸”à¹Œ
""")
    
    print("\n" + "="*70)
    print("ğŸ’¡ à¸ªà¸£à¸¸à¸›:")
    print("="*70)
    print("""
âœ… Fine-tuning â†’ à¸ªà¸­à¸™ "à¸—à¸±à¸à¸©à¸°" (à¸£à¸¹à¹‰à¸§à¸´à¸˜à¸µà¹€à¸‚à¸µà¸¢à¸™ format, tone, structure)
âœ… RAG â†’ à¸›à¹‰à¸­à¸™ "à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰" (à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸šà¸£à¸™à¸”à¹Œà¹à¸šà¸š real-time à¸ˆà¸²à¸ brands.json)

à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ: à¸£à¸­à¸‡à¸£à¸±à¸šà¹à¸šà¸£à¸™à¸”à¹Œà¹ƒà¸«à¸¡à¹ˆà¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸ˆà¸³à¸à¸±à¸”à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ retrain! ğŸš€
    """)


def demo_live_inference():
    """
    Demo: à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ˆà¸£à¸´à¸‡ (à¸•à¹‰à¸­à¸‡à¸¡à¸µ fine-tuned model à¹à¸¥à¸° brands.json à¸—à¸µà¹ˆà¸¡à¸µ TechZone)
    
    à¸§à¸´à¸˜à¸µà¹€à¸à¸´à¹ˆà¸¡à¹à¸šà¸£à¸™à¸”à¹Œà¹ƒà¸«à¸¡à¹ˆ:
    1. à¹à¸à¹‰à¹„à¸‚ ../../module2/data/raw/brands_v2.json à¹€à¸à¸´à¹ˆà¸¡ TechZone
    2. à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ retrain model
    3. Run script à¸™à¸µà¹‰à¹„à¸”à¹‰à¹€à¸¥à¸¢!
    """
    
    print("\n" + "="*70)
    print("ğŸš€ LIVE DEMO: à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸šà¹à¸šà¸£à¸™à¸”à¹Œà¹ƒà¸«à¸¡à¹ˆà¸ˆà¸£à¸´à¸‡à¹†")
    print("="*70)
    
    # à¸ªà¸¡à¸¡à¸•à¸´à¸§à¹ˆà¸²à¸„à¸¸à¸“ fine-tune à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ à¹à¸¥à¸°à¹€à¸à¸´à¹ˆà¸¡ TechZone à¹ƒà¸™ brands.json à¹à¸¥à¹‰à¸§
    lora_adapter_path = "../models/qwen-7b-ai-director"
    
    if not os.path.exists(lora_adapter_path):
        print(f"\nâŒ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸à¸š fine-tuned model à¸—à¸µà¹ˆ {lora_adapter_path}")
        print("   â†’ à¸•à¹‰à¸­à¸‡à¸£à¸±à¸™ finetune_lora.py à¸à¹ˆà¸­à¸™à¸„à¸£à¸±à¸š")
        return
    
    # à¸ªà¸£à¹‰à¸²à¸‡ inference engine à¸à¸£à¹‰à¸­à¸¡ RAG
    inference = AIDirectorRAGInference(
        lora_adapter_path=lora_adapter_path,
        brands_json_path="../../module2/data/raw/brands_v2.json"
    )
    
    print("\nğŸ“‹ à¹à¸šà¸£à¸™à¸”à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¹ƒà¸™ RAG database:")
    available_brands = inference.rag.list_available_brands()
    print(f"   {', '.join(available_brands)}")
    
    # à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸šà¹à¸šà¸£à¸™à¸”à¹Œà¹ƒà¸«à¸¡à¹ˆ
    print("\n" + "-"*70)
    print("Test 1: Generate Caption à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸šà¸£à¸™à¸”à¹Œà¹ƒà¸«à¸¡à¹ˆ 'TechZone'")
    print("-"*70)
    
    try:
        caption = inference.generate_caption(
            brand_name="TechZone",
            context="Gaming mouse launch"
        )
        print(f"\nğŸ“ Output:\n{caption}")
    except Exception as e:
        print(f"âŒ Error: {e}")
        print("   â†’ à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µ 'TechZone' à¹ƒà¸™ brands_v2.json à¸«à¸£à¸·à¸­à¸¢à¸±à¸‡")
    
    # à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸šà¹à¸šà¸£à¸™à¸”à¹Œà¹€à¸à¹ˆà¸²
    print("\n" + "-"*70)
    print("Test 2: Generate Caption à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸šà¸£à¸™à¸”à¹Œà¹€à¸”à¸´à¸¡ 'CoffeeLab'")
    print("-"*70)
    
    caption = inference.generate_caption(
        brand_name="CoffeeLab",
        context="Weekend special promotion"
    )
    print(f"\nğŸ“ Output:\n{caption}")


if __name__ == "__main__":
    # à¹€à¸£à¸µà¸¢à¸ demo à¹à¸šà¸š conceptual à¸à¹ˆà¸­à¸™ (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ GPU)
    demo_comparison()
    
    # à¸–à¹‰à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸šà¸ˆà¸£à¸´à¸‡ à¹ƒà¸«à¹‰ uncomment à¸šà¸£à¸£à¸—à¸±à¸”à¸™à¸µà¹‰
    # (à¸•à¹‰à¸­à¸‡à¸¡à¸µ GPU à¹à¸¥à¸° fine-tuned model à¸à¸£à¹‰à¸­à¸¡)
    # demo_live_inference()
