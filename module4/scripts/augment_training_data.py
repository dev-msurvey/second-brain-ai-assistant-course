#!/usr/bin/env python3
"""
Data Augmentation Script for Module 4

‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡∏™‡∏°‡∏°‡∏ï‡∏¥ (Synthetic Brands) ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°
‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô train.jsonl ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Overfitting

‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏î‡∏¥‡∏°:
- ‡∏°‡∏µ‡πÅ‡∏Ñ‡πà 3 ‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå: CoffeeLab (‡∏Å‡∏≤‡πÅ‡∏ü), FitFlow (‡∏ü‡∏¥‡∏ï‡πÄ‡∏ô‡∏™), GreenLeaf (‡∏ú‡∏±‡∏Å)
- ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á hallucinate ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà

‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:
- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡∏™‡∏°‡∏°‡∏ï‡∏¥ 6-8 ‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°
- ‡πÄ‡∏û‡∏¥‡πà‡∏° 30-50 samples ‡∏•‡∏á train.jsonl
- ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤ "Brand tone ‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ï‡∏≤‡∏°‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°"
"""

import json
import random
from pathlib import Path
from typing import List, Dict


# ========== Synthetic Brand Definitions ==========

SYNTHETIC_BRANDS = [
    {
        "name": "PetPals",
        "industry": "Pet Care",
        "description": "‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏û‡∏£‡∏µ‡πÄ‡∏°‡∏µ‡πà‡∏¢‡∏°",
        "tone": ["‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å", "‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô", "‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á"],
        "target_audience": "‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á 25-45 ‡∏õ‡∏µ",
        "core_values": ["Love Your Pets", "Premium Quality", "Happy Tails"],
        "emoji_style": ["üê∂", "üê±", "‚ù§Ô∏è", "üéæ", "ü¶¥"],
        "hashtags": ["#PetPals", "#HappyPets", "‡∏ï‡∏±‡∏ß‡πÄ‡∏Å‡πà‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏°‡πà"]
    },
    {
        "name": "SpeedyLoans",
        "industry": "Finance/Banking",
        "description": "‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏î‡πà‡∏ß‡∏ô ‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡πÑ‡∏ß ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ AI",
        "tone": ["‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠", "‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û", "‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß"],
        "target_audience": "‡∏ú‡∏π‡πâ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ ‡∏ß‡∏±‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô 30-55 ‡∏õ‡∏µ",
        "core_values": ["Fast Approval", "Transparent", "Customer First"],
        "emoji_style": ["üí∞", "‚ö°", "üìä", "‚úÖ", "üè¶"],
        "hashtags": ["#SpeedyLoans", "#FastApproval", "#SmartFinance"]
    },
    {
        "name": "LuxStay",
        "industry": "Hotel/Hospitality",
        "description": "‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°‡∏ö‡∏π‡∏ï‡∏¥‡∏Å ‡∏´‡πâ‡∏≠‡∏á‡∏û‡∏±‡∏Å luxury ‡∏ó‡πà‡∏≤‡∏°‡∏Å‡∏•‡∏≤‡∏á‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥",
        "tone": ["‡∏´‡∏£‡∏π‡∏´‡∏£‡∏≤", "‡∏™‡∏á‡∏ö", "exclusive"],
        "target_audience": "‡∏ô‡∏±‡∏Å‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏£‡∏∞‡∏î‡∏±‡∏ö high-end 35-60 ‡∏õ‡∏µ",
        "core_values": ["Luxury Experience", "Nature Harmony", "Exclusive Service"],
        "emoji_style": ["üè®", "‚ú®", "üåø", "üõÅ", "üç∑"],
        "hashtags": ["#LuxStay", "#LuxuryEscape", "#PrivateRetreat"]
    },
    {
        "name": "EduKid",
        "industry": "Education/Children",
        "description": "‡πÅ‡∏≠‡∏õ‡πÄ‡∏Å‡∏°‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏î‡πá‡∏Å ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô",
        "tone": ["‡∏™‡∏ô‡∏∏‡∏Å‡∏™‡∏ô‡∏≤‡∏ô", "‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à", "‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£"],
        "target_audience": "‡∏û‡πà‡∏≠‡πÅ‡∏°‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏•‡∏π‡∏Å‡∏≠‡∏≤‡∏¢‡∏∏ 3-12 ‡∏õ‡∏µ",
        "core_values": ["Learn Through Play", "Safe Content", "Child Development"],
        "emoji_style": ["üéì", "üéÆ", "üåà", "üß©", "‚≠ê"],
        "hashtags": ["#EduKid", "#PlayToLearn", "#SmartKids"]
    },
    {
        "name": "UrbanRide",
        "industry": "Transportation",
        "description": "‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ e-scooter ‡πÅ‡∏•‡∏∞ e-bike ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á",
        "tone": ["‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢", "eco-friendly", "‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏™‡∏ö‡∏≤‡∏¢"],
        "target_audience": "‡∏Ñ‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÉ‡∏´‡∏ç‡πà 20-40 ‡∏õ‡∏µ",
        "core_values": ["Green Mobility", "Urban Convenience", "Affordable"],
        "emoji_style": ["üõ¥", "üå±", "üåÜ", "‚ö°", "üö¥"],
        "hashtags": ["#UrbanRide", "#EcoCommute", "#CityMobility"]
    },
    {
        "name": "HealthHub",
        "industry": "Healthcare/Telemedicine",
        "description": "‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏´‡∏°‡∏≠‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå 24/7",
        "tone": ["‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£", "‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û", "‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à"],
        "target_audience": "‡∏ó‡∏∏‡∏Å‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏¢ ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏π‡πâ‡∏™‡∏π‡∏á‡∏≠‡∏≤‡∏¢‡∏∏",
        "core_values": ["Accessible Healthcare", "Expert Care", "Always Available"],
        "emoji_style": ["üè•", "üë®‚Äç‚öïÔ∏è", "üíä", "üì±", "‚ù§Ô∏è"],
        "hashtags": ["#HealthHub", "#OnlineDoctor", "#CareAnywhere"]
    },
    {
        "name": "FoodieBox",
        "industry": "Food Delivery/Subscription",
        "description": "‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥ ‡∏™‡πà‡∏á‡∏ñ‡∏∂‡∏á‡∏ö‡πâ‡∏≤‡∏ô ‡∏°‡∏µ‡∏™‡∏π‡∏ï‡∏£‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå",
        "tone": ["‡∏≠‡∏£‡πà‡∏≠‡∏¢", "‡∏™‡∏ô‡∏∏‡∏Å", "‡∏Ñ‡∏£‡∏µ‡πÄ‡∏≠‡∏ó‡∏µ‡∏ü"],
        "target_audience": "‡∏Ñ‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô millennial 25-40 ‡∏õ‡∏µ",
        "core_values": ["Fresh Ingredients", "Easy Cooking", "New Experiences"],
        "emoji_style": ["üç±", "üçú", "üë®‚Äçüç≥", "üì¶", "‚ú®"],
        "hashtags": ["#FoodieBox", "#HomeCooking", "#WeeklyRecipes"]
    },
    {
        "name": "GlowLab",
        "industry": "Cosmetics/Skincare",
        "description": "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥",
        "tone": ["‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•", "‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à", "natural beauty"],
        "target_audience": "‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á‡∏ß‡∏±‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô 20-45 ‡∏õ‡∏µ",
        "core_values": ["Natural Ingredients", "Gentle Care", "Thai Beauty Wisdom"],
        "emoji_style": ["‚ú®", "üå∏", "üíÑ", "üß¥", "üíÜ‚Äç‚ôÄÔ∏è"],
        "hashtags": ["#GlowLab", "#NaturalGlow", "#ThaiBeauty"]
    }
]


# ========== Template Generators ==========

def generate_caption_sample(brand: Dict) -> Dict:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á caption generation sample"""
    
    contexts = ["Product launch", "Weekend post", "Customer testimonial", "Behind the scenes"]
    context = random.choice(contexts)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á output ‡∏ï‡∏≤‡∏° brand tone
    emoji = random.choice(brand["emoji_style"])
    hashtag = random.choice(brand["hashtags"])
    
    if "‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å" in brand["tone"]:
        output = f"{emoji} ‡∏£‡∏±‡∏Å‡∏©‡πå‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á ‡∏î‡πâ‡∏ß‡∏¢‡πÉ‡∏à ‡∏ó‡∏µ‡πà {brand['name']} {hashtag}"
    elif "‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠" in brand["tone"]:
        output = f"{emoji} {brand['core_values'][0]} ‡∏Å‡∏±‡∏ö {brand['name']} - {brand['description'][:30]}... {hashtag}"
    elif "‡∏´‡∏£‡∏π‡∏´‡∏£‡∏≤" in brand["tone"]:
        output = f"{emoji} Experience {brand['core_values'][0]} at {brand['name']} {hashtag}"
    elif "‡∏™‡∏ô‡∏∏‡∏Å‡∏™‡∏ô‡∏≤‡∏ô" in brand["tone"]:
        output = f"{emoji} ‡∏°‡∏≤‡∏™‡∏ô‡∏∏‡∏Å‡∏Å‡∏±‡∏ô‡πÄ‡∏ñ‡∏≠‡∏∞! ‡∏ó‡∏µ‡πà {brand['name']} {hashtag}"
    elif "‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢" in brand["tone"]:
        output = f"{emoji} {brand['core_values'][0]} - {brand['name']} ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì {hashtag}"
    else:
        output = f"{emoji} ‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö {brand['name']} {hashtag}"
    
    return {
        "instruction": f"‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô caption ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå {context} ‡∏Ç‡∏≠‡∏á {brand['name']}",
        "input": f"Brand: {brand['name']}\nTone: {', '.join(brand['tone'])}\nContext: {context}",
        "output": output,
        "metadata": {
            "brand": brand["name"],
            "task": "caption_generation",
            "context": context.lower().replace(" ", "_"),
            "quality": "synthetic"
        }
    }


def generate_brand_voice_sample(brand: Dict) -> Dict:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á brand voice adaptation sample"""
    
    generic_messages = [
        "‡∏•‡∏≠‡∏á‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà‡∏Å‡∏±‡∏ô‡πÄ‡∏ñ‡∏≠‡∏∞",
        "‡∏°‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏â‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏≤",
        "‡∏™‡∏ô‡πÉ‡∏à‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢",
        "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©"
    ]
    
    generic_msg = random.choice(generic_messages)
    emoji = random.choice(brand["emoji_style"])
    tone_keyword = brand["tone"][0]
    
    # Adapt ‡∏ï‡∏≤‡∏° brand voice
    adapted = f"{emoji} {generic_msg} {tone_keyword}‡∏Å‡∏±‡∏ö {brand['name']}"
    
    return {
        "instruction": f"‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö brand voice ‡∏Ç‡∏≠‡∏á {brand['name']}",
        "input": f"Brand: {brand['name']}\nTone: {', '.join(brand['tone'])}\nMessage: {generic_msg}",
        "output": adapted,
        "metadata": {
            "brand": brand["name"],
            "task": "brand_voice_adaptation",
            "source_type": "generic_to_branded",
            "quality": "synthetic"
        }
    }


def generate_key_messages_sample(brand: Dict) -> Dict:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á key messages generation sample"""
    
    values = brand["core_values"]
    
    key_messages = "\n".join([f"‚Ä¢ {value}" for value in values[:3]])
    
    return {
        "instruction": f"‡∏™‡∏£‡πâ‡∏≤‡∏á key messages ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Ñ‡∏°‡πÄ‡∏õ‡∏ç‡∏Ç‡∏≠‡∏á {brand['name']}",
        "input": f"Brand: {brand['name']}\nIndustry: {brand['industry']}\nDescription: {brand['description']}\nCore Values: {', '.join(values)}",
        "output": key_messages,
        "metadata": {
            "brand": brand["name"],
            "task": "key_messages_generation",
            "quality": "synthetic"
        }
    }


# ========== Main Augmentation Logic ==========

def augment_training_data(
    input_train_path: str = "../module3/data/generated/train_v2.jsonl",
    output_train_path: str = "../module3/data/generated/train_v2_augmented.jsonl",
    samples_per_brand: int = 5
) -> None:
    """
    ‡πÄ‡∏û‡∏¥‡πà‡∏° synthetic brand samples ‡∏•‡∏á‡πÉ‡∏ô train_v2.jsonl
    
    Args:
        input_train_path: Path ‡∏Ç‡∏≠‡∏á train_v2.jsonl ‡πÄ‡∏î‡∏¥‡∏°
        output_train_path: Path ‡∏Ç‡∏≠‡∏á train_v2.jsonl ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ synthetic data
        samples_per_brand: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô samples ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå (default: 5)
    """
    
    print("\n" + "="*80)
    print("üîß Data Augmentation: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡∏™‡∏°‡∏°‡∏ï‡∏¥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Overfitting")
    print("="*80)
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î train.jsonl ‡πÄ‡∏î‡∏¥‡∏°
    input_path = Path(input_train_path)
    
    if not input_path.exists():
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {input_train_path}")
        return
    
    original_samples = []
    with open(input_path, "r", encoding="utf-8") as f:
        for line in f:
            original_samples.append(json.loads(line))
    
    print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°:")
    print(f"   ‚Ä¢ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô samples: {len(original_samples)}")
    
    # ‡∏ô‡∏±‡∏ö‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå
    original_brands = {}
    for sample in original_samples:
        brand = sample.get("metadata", {}).get("brand", "Unknown")
        original_brands[brand] = original_brands.get(brand, 0) + 1
    
    print(f"   ‚Ä¢ ‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡πÄ‡∏î‡∏¥‡∏°: {list(original_brands.keys())}")
    for brand, count in original_brands.items():
        print(f"     - {brand}: {count} samples")
    
    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á synthetic samples
    print(f"\nüé® ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡∏™‡∏°‡∏°‡∏ï‡∏¥ {len(SYNTHETIC_BRANDS)} ‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå...")
    
    synthetic_samples = []
    
    for brand in SYNTHETIC_BRANDS:
        print(f"\n   ‚Ä¢ {brand['name']} ({brand['industry']})")
        print(f"     Tone: {', '.join(brand['tone'])}")
        
        brand_samples = []
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á samples ‡πÅ‡∏ö‡∏ö‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢
        for _ in range(samples_per_brand):
            task_type = random.choice(["caption", "voice", "key_messages"])
            
            if task_type == "caption":
                sample = generate_caption_sample(brand)
            elif task_type == "voice":
                sample = generate_brand_voice_sample(brand)
            else:
                sample = generate_key_messages_sample(brand)
            
            brand_samples.append(sample)
        
        synthetic_samples.extend(brand_samples)
        print(f"     ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á {len(brand_samples)} samples")
    
    # 3. ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏° + synthetic
    all_samples = original_samples + synthetic_samples
    
    # Shuffle ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô
    random.shuffle(all_samples)
    
    # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô train_augmented.jsonl
    output_path = Path(output_train_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        for sample in all_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + "\n")
    
    print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà: {output_path}")
    
    # 5. ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà:")
    print(f"   ‚Ä¢ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô samples ‡∏£‡∏ß‡∏°: {len(all_samples)}")
    print(f"     - ‡πÄ‡∏î‡∏¥‡∏°: {len(original_samples)}")
    print(f"     - ‡πÄ‡∏û‡∏¥‡πà‡∏°: {len(synthetic_samples)}")
    
    # ‡∏ô‡∏±‡∏ö‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà
    all_brands = {}
    for sample in all_samples:
        brand = sample.get("metadata", {}).get("brand", "Unknown")
        all_brands[brand] = all_brands.get(brand, 0) + 1
    
    print(f"\n   ‚Ä¢ ‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ({len(all_brands)} brands):")
    for brand, count in sorted(all_brands.items(), key=lambda x: x[1], reverse=True):
        status = "‡πÄ‡∏î‡∏¥‡∏°" if brand in original_brands else "‡πÉ‡∏´‡∏°‡πà"
        print(f"     - {brand}: {count} samples ({status})")
    
    print("\n" + "="*80)
    print("üí° ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ:")
    print("="*80)
    print(f"""
1. ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á train_augmented.jsonl ‡πÅ‡∏•‡πâ‡∏ß ({len(all_samples)} samples)

2. ‚è≠Ô∏è  ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç finetune_lora.py ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà:
   
   ‡πÄ‡∏î‡∏¥‡∏°:  train_dataset = load_dataset("json", data_files="{{"train": "train.jsonl"}}")
   ‡πÉ‡∏´‡∏°‡πà:  train_dataset = load_dataset("json", data_files="{{"train": "train_augmented.jsonl"}}")

3. ‚è≠Ô∏è  Fine-tune ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ö‡∏ô Colab
   ‚Üí python finetune_lora.py

4. ‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:
   ‚Ä¢ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå ({len(all_brands)} brands)
   ‚Ä¢ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤ Tone ‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ï‡∏≤‡∏°‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°
   ‚Ä¢ ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á hallucination ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà
   ‚Ä¢ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ RAG ‡∏£‡πà‡∏ß‡∏°‡∏î‡πâ‡∏ß‡∏¢ = ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö! üöÄ
""")


def show_sample_preview(n_samples: int = 3):
    """‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á synthetic samples ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á"""
    
    print("\n" + "="*80)
    print("üëÄ Preview: ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Synthetic Samples")
    print("="*80)
    
    for i, brand in enumerate(SYNTHETIC_BRANDS[:n_samples]):
        print(f"\n{'‚îÄ'*80}")
        print(f"‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå {i+1}: {brand['name']} ({brand['industry']})")
        print(f"Tone: {', '.join(brand['tone'])}")
        print(f"{'‚îÄ'*80}")
        
        # Caption sample
        caption_sample = generate_caption_sample(brand)
        print(f"\n1Ô∏è‚É£  Caption Generation:")
        print(f"   Instruction: {caption_sample['instruction']}")
        print(f"   Output: {caption_sample['output']}")
        
        # Brand voice sample
        voice_sample = generate_brand_voice_sample(brand)
        print(f"\n2Ô∏è‚É£  Brand Voice Adaptation:")
        print(f"   Instruction: {voice_sample['instruction']}")
        print(f"   Output: {voice_sample['output']}")
        
        # Key messages sample
        key_sample = generate_key_messages_sample(brand)
        print(f"\n3Ô∏è‚É£  Key Messages:")
        print(f"   Output:\n{key_sample['output']}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "preview":
        # ‡πÅ‡∏™‡∏î‡∏á preview ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå)
        show_sample_preview(n_samples=8)
    else:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
        augment_training_data(
            input_train_path="../module3/data/generated/train_v2.jsonl",
            output_train_path="../module3/data/generated/train_v2_augmented.jsonl",
            samples_per_brand=5  # ‡∏™‡∏£‡πâ‡∏≤‡∏á 5 samples ‡∏ï‡πà‡∏≠‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå = 8 brands √ó 5 = 40 samples ‡πÄ‡∏û‡∏¥‡πà‡∏°
        )
