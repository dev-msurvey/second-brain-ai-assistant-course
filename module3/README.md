# Module 3: Dataset Generation for AI Director Fine-tuning

> ‡∏™‡∏£‡πâ‡∏≤‡∏á training datasets ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• brands ‡πÅ‡∏•‡∏∞ campaigns ‡πÄ‡∏û‡∏∑‡πà‡∏≠ fine-tune AI Director models

## üìã Overview

Module ‡∏ô‡∏µ‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á instruction-response pairs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning AI models ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ marketing ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ brand

### Dataset Types

1. **Caption Generation** - ‡∏™‡∏£‡πâ‡∏≤‡∏á captions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Instagram/TikTok
2. **Campaign Brief Creation** - ‡∏™‡∏£‡πâ‡∏≤‡∏á campaign briefs
3. **Brand Voice Adaptation** - ‡∏õ‡∏£‡∏±‡∏ö content ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö brand voice
4. **Content Strategy** - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤

## üöÄ Quick Start

### Generate Datasets

```bash
cd module3
python scripts/generate_dataset.py
```

### Output Structure

```
module3/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ generated/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.jsonl              # Training set (80%)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val.jsonl                # Validation set (10%)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test.jsonl               # Test set (10%)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ caption_dataset.jsonl    # Caption-specific dataset
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ campaign_brief_dataset.jsonl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ brand_voice_dataset.jsonl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ content_strategy_dataset.jsonl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json            # Dataset statistics
‚îÇ   ‚îî‚îÄ‚îÄ samples/
‚îÇ       ‚îî‚îÄ‚îÄ sample_caption.jsonl     # Example format
```

## üìä Dataset Format

### JSONL Format (JSON Lines)

Each line is a valid JSON object:

```jsonl
{
  "instruction": "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô caption ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CoffeeLab ‡πÉ‡∏ä‡πâ tone: friendly, premium, modern",
  "input": "Brand: CoffeeLab\nTagline: Craft Your Perfect Morning\nTarget: young professionals",
  "output": "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ä‡πâ‡∏≤‡∏ß‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡πÅ‡∏ü‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πà ‚òïÔ∏è #CoffeeLab",
  "metadata": {
    "brand": "CoffeeLab",
    "task": "caption_generation",
    "platform": "instagram/tiktok",
    "quality": "good"
  }
}
```

### Fields

- **instruction**: ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà model ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ (task description)
- **input**: context ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á output
- **output**: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ model ‡∏™‡∏£‡πâ‡∏≤‡∏á
- **metadata**: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞ filtering

## üéØ Dataset Generation Strategy

### 1. Caption Generation Dataset

**Source**: `content_examples.caption_good` ‡∏à‡∏≤‡∏Å brands.json

**Approach**:
- ‡πÉ‡∏ä‡πâ good caption examples ‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞ brand
- ‡∏™‡∏£‡πâ‡∏≤‡∏á variations ‡∏ï‡∏≤‡∏° context (product launch, weekend post, etc.)
- ‡∏£‡∏ß‡∏° brand tone, target audience ‡πÉ‡∏ô instruction

**Example**:
```json
{
  "instruction": "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô caption ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CoffeeLab ‡πÉ‡∏ä‡πâ tone: friendly, premium, modern",
  "input": "Brand: CoffeeLab\nTagline: Craft Your Perfect Morning",
  "output": "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ä‡πâ‡∏≤‡∏ß‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡πÅ‡∏ü‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πà ‚òïÔ∏è #CoffeeLab"
}
```

### 2. Campaign Brief Dataset

**Source**: campaigns.json

**Approach**:
- ‡πÉ‡∏ä‡πâ existing campaign briefs ‡πÄ‡∏õ‡πá‡∏ô ground truth
- ‡∏£‡∏ß‡∏° objectives, key messages
- ‡πÄ‡∏û‡∏¥‡πà‡∏° brand context

**Example**:
```json
{
  "instruction": "‡∏™‡∏£‡πâ‡∏≤‡∏á campaign brief ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CoffeeLab",
  "input": "Objectives: Launch new Cold Brew, Increase awareness 30%",
  "output": "Campaign: Cold Brew Launch 2025\nGoal: ‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß Cold Brew..."
}
```

### 3. Brand Voice Adaptation Dataset

**Source**: Synthetic - ‡πÅ‡∏õ‡∏•‡∏á generic messages ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö brand voice

**Approach**:
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å generic message
- ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö tone, values ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ brand
- ‡πÄ‡∏û‡∏¥‡πà‡∏° brand-specific elements (emojis, hashtags)

**Example**:
```json
{
  "instruction": "‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö brand voice ‡∏Ç‡∏≠‡∏á CoffeeLab",
  "input": "Message: ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß‡πÅ‡∏•‡πâ‡∏ß",
  "output": "‚òïÔ∏è ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß‡πÅ‡∏•‡πâ‡∏ß #CraftYourMorning"
}
```

### 4. Content Strategy Dataset

**Source**: campaigns.json (timeline, content_requirements)

**Approach**:
- ‡∏™‡∏£‡πâ‡∏≤‡∏á strategy ‡∏à‡∏≤‡∏Å campaign objectives
- ‡∏£‡∏ß‡∏° timeline phases
- ‡∏£‡∏∞‡∏ö‡∏∏ content requirements

## üìà Dataset Statistics

**Current Dataset** (Generated: 2026-01-04):

| Dataset Type | Samples | Description |
|-------------|---------|-------------|
| Caption Generation | 15 | Instagram/TikTok captions |
| Campaign Brief | 6 | Campaign planning documents |
| Brand Voice Adaptation | 15 | Generic to branded content |
| Content Strategy | 3 | Strategic content plans |
| **Total** | **39** | All training samples |

**Data Splits**:
- Training: 31 samples (80%)
- Validation: 4 samples (10%)
- Test: 4 samples (10%)

## üîß Technical Details

### Dependencies

```python
# Core
import json
import random
from pathlib import Path
from typing import List, Dict, Any
from loguru import logger
```

No external ML libraries required for generation (uses rule-based synthesis)

### Input Data

- **brands.json**: 3 brands with comprehensive v2 structure
  - CoffeeLab (coffee shop)
  - FitFlow (fitness center)
  - GreenLeaf (organic food delivery)

- **campaigns.json**: 3 campaigns
  - Cold Brew Launch 2025
  - New Year Transformation
  - Farm to Table Series

### Data Quality

**Good Examples (from brands.json)**:
- Real captions from content_examples
- Verified to match brand voice
- Include appropriate emojis and hashtags

**Synthesized Examples**:
- Generated with context variations
- Follow brand guidelines
- Quality: "synthesized" in metadata

## üéì Key Learnings

### 1. Data Quality > Quantity

39 samples ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ 1000 samples ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥:
- ‡πÉ‡∏ä‡πâ real examples ‡∏à‡∏≤‡∏Å brands v2 data
- Synthesize ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ rules ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
- Validate ‡∏ó‡∏∏‡∏Å sample ‡∏Å‡πà‡∏≠‡∏ô save

### 2. Few-Shot Learning

Dataset ‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏ï‡πà‡∏°‡∏µ diversity ‡∏™‡∏π‡∏á:
- 3 brands √ó multiple contexts
- Different task types (caption, brief, strategy)
- Rich metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö filtering

### 3. Instruction Format Matters

Structure instruction-input-output ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô:
```
Instruction: ‡∏≠‡∏∞‡πÑ‡∏£ (task)
Input: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á (context)
Output: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (expected result)
```

### 4. Metadata for Debugging

‡πÄ‡∏Å‡πá‡∏ö metadata ‡∏Ñ‡∏£‡∏ö:
- brand, task, context
- quality indicator (good/synthesized)
- timestamp, version

## üîÆ Next Steps (Module 4)

### Fine-tuning with Generated Datasets

1. **Choose Base Model**: 
   - Llama 3.1 8B, Mistral 7B, ‡∏´‡∏£‡∏∑‡∏≠ Qwen 7B
   - Thai language support important

2. **Fine-tuning Approach**:
   - LoRA (Low-Rank Adaptation) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö efficiency
   - Train ‡∏ö‡∏ô train.jsonl (31 samples)
   - Validate ‡∏ö‡∏ô val.jsonl (4 samples)

3. **Evaluation**:
   - Test ‡∏ö‡∏ô test.jsonl (4 samples)
   - Manual review brand voice consistency
   - Compare ‡∏Å‡∏±‡∏ö base model

4. **Deployment**:
   - Export fine-tuned model
   - Integrate ‡∏Å‡∏±‡∏ö AI Director system
   - A/B test ‡∏Å‡∏±‡∏ö base model

## üìö References

### Related Files

- **Module 2**: [../module2/README.md](../module2/README.md)
  - Source data: brands.json, campaigns.json
  - ETL pipeline ‡πÅ‡∏•‡∏∞ data structure

- **Module 2 Lesson Learned**: [../module2/LESSON_LEARNED.md](../module2/LESSON_LEARNED.md)
  - 7-dimensional data modeling framework
  - Data quality best practices

### HuggingFace Format

Dataset format compatible with:
- `datasets` library: `load_dataset("json", data_files="train.jsonl")`
- Direct fine-tuning with `transformers`
- Compatible with Axolotl, LLaMA Factory

## üìù Usage Examples

### Load Dataset in Python

```python
import json

# Load JSONL
with open("data/generated/train.jsonl", 'r') as f:
    train_data = [json.loads(line) for line in f]

print(f"Training samples: {len(train_data)}")
print(f"First sample: {train_data[0]}")
```

### Load with HuggingFace Datasets

```python
from datasets import load_dataset

dataset = load_dataset(
    "json",
    data_files={
        "train": "data/generated/train.jsonl",
        "validation": "data/generated/val.jsonl",
        "test": "data/generated/test.jsonl"
    }
)

print(dataset)
# DatasetDict({
#     train: Dataset({
#         features: ['instruction', 'input', 'output', 'metadata'],
#         num_rows: 31
#     })
#     validation: Dataset({...})
#     test: Dataset({...})
# })
```

### Filter by Task Type

```python
# Load all captions
captions = [
    sample for sample in train_data 
    if sample['metadata']['task'] == 'caption_generation'
]

print(f"Caption samples: {len(captions)}")
```

## ‚úÖ Validation Checklist

- [x] JSONL format valid (one JSON per line)
- [x] All samples have instruction, input, output
- [x] Metadata includes brand, task, quality
- [x] Train/val/test splits created (80/10/10)
- [x] Sample files created for documentation
- [x] Output statistics logged
- [x] No data leakage between splits

## üéØ Success Criteria

Module 3 ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÄ‡∏°‡∏∑‡πà‡∏≠:

1. ‚úÖ Generate datasets ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (39 samples)
2. ‚úÖ JSONL format ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
3. ‚úÖ ‡∏°‡∏µ train/val/test splits
4. ‚úÖ Dataset ‡∏°‡∏µ diversity (4 task types, 3 brands)
5. ‚úÖ Documentation ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
6. ‚è≠Ô∏è Ready ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning (Module 4)

---

**Module 3 Status**: ‚úÖ COMPLETE

**Generated**: 2026-01-04
**Total Samples**: 39 (31 train / 4 val / 4 test)
**Next**: Module 4 - Model Fine-tuning
